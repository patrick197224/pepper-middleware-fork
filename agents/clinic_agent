#!/usr/bin/env python3
"""
Multi-Agent System for Clinic Patient Communication

This script implements a multi-agent system using OpenAI Agents Framework to provide
patient communication, clinic information retrieval, and appointment management.

The system consists of:
1. The Orchestrator: Automatically routes patient requests to the appropriate agent
2. The Receptionist: Answers questions about the clinic using RAG system
3. The Appointment Manager: Handles appointment scheduling and database operations

Required packages:
pip install langchain-openai langchain-classic langchain-community langchain-core langchain-text-splitters chromadb PyPDF2 pandas
"""

import os
import warnings
import sqlite3
import requests
import tempfile
import paramiko
import re
from typing import Dict, Optional, List
from datetime import datetime, timedelta
from contextlib import contextmanager
from agents import Agent, Runner, function_tool, SQLiteSession


# Import Pepper audio module
try:
    import sys
    import importlib.util
    # Handle module name with dash - get the directory of this file
    current_dir = os.path.dirname(os.path.abspath(__file__))
    pepper_audio_path = os.path.join(current_dir, "pepper-audio.py")
    spec = importlib.util.spec_from_file_location("pepper_audio", pepper_audio_path)
    pepper_audio = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(pepper_audio)
    speech_to_text_from_pepper = pepper_audio.speech_to_text_from_pepper
    speech_to_text_interactive = pepper_audio.speech_to_text_interactive
    PEPPER_AUDIO_AVAILABLE = True
except Exception as e:
    print(f"Warning: Could not load pepper-audio module: {e}")
    print("Install required packages: pip install paramiko openai")
    PEPPER_AUDIO_AVAILABLE = False
    speech_to_text_from_pepper = None
    speech_to_text_interactive = None

# Import audio.py module for get_user_text()
try:
    import sys
    import importlib.util
    current_dir = os.path.dirname(os.path.abspath(__file__))
    audio_path = os.path.join(current_dir, "audio.py")
    spec = importlib.util.spec_from_file_location("audio_module", audio_path)
    audio_module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(audio_module)
    get_user_text = audio_module.get_user_text
    AUDIO_MODULE_AVAILABLE = True
except Exception as e:
    print(f"Warning: Could not load audio module: {e}")
    AUDIO_MODULE_AVAILABLE = False
    get_user_text = None

# ============================================================================
# PEPPER ROBOT CONFIGURATION
# ============================================================================

PEPPER_MIDDLEWARE_URL = os.environ.get("PEPPER_MIDDLEWARE_URL", "http://172.30.36.71:5000")
TTS_LANGUAGE = os.environ.get("TTS_LANGUAGE", "English")
TTS_ANIMATED = True  # Use animated speech with gestures

# Suppress ResourceWarnings from asyncio (they're harmless)
warnings.filterwarnings("ignore", category=ResourceWarning)


# ============================================================================
# RAG SYSTEM INITIALIZATION
# ============================================================================

print("Initializing RAG system for clinic information...")

try:
    from langchain_openai import ChatOpenAI, OpenAIEmbeddings
    from langchain_classic.chains.retrieval import create_retrieval_chain
    from langchain_classic.chains.combine_documents import create_stuff_documents_chain
    from langchain_core.prompts import ChatPromptTemplate
    from langchain_community.vectorstores import Chroma
    from langchain_text_splitters import RecursiveCharacterTextSplitter
    import glob
    import PyPDF2
    
    # Load documents
    documents = []
    for filename in glob.glob("*.txt"):
        with open(filename, "r", encoding="utf-8") as f:
            documents.append(f.read())
    
    for filename in glob.glob("*.pdf"):
        try:
            with open(filename, "rb") as f:
                reader = PyPDF2.PdfReader(f)
                pdf_text = "".join(page.extract_text() or "" for page in reader.pages)
                documents.append(pdf_text)
        except Exception as e:
            print(f"Error reading {filename}: {e}")
    
    if not documents:
        print("Warning: No documents found. RAG system will not work properly.")
        rag_qa_chain = None
    else:
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
        docs = text_splitter.create_documents(documents)
        
        embeddings = OpenAIEmbeddings(
            openai_api_key=os.environ["OPENAI_API_KEY"],
            model="text-embedding-ada-002"
        )
        vectorstore = Chroma.from_documents(docs, embeddings)
        
        llm = ChatOpenAI(
            openai_api_key=os.environ["OPENAI_API_KEY"],
            model_name="gpt-3.5-turbo"
        )
        
        system_prompt = (
            "Use the following context about GreenOak Family Practice clinic to answer the question. "
            "If the information is not in the context, say so. Be helpful and accurate.\n\n"
            "{context}"
        )
        prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            ("human", "{input}")
        ])
        
        combine_docs_chain = create_stuff_documents_chain(llm, prompt)
        rag_qa_chain = create_retrieval_chain(vectorstore.as_retriever(), combine_docs_chain)
        print(f"âœ“ RAG system initialized with {len(documents)} document(s)")
        